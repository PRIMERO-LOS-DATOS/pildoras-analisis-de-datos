library(DBI)
dbname <- 'base-de-datos'
host <- 'us-east.connect.psdb.cloud'
port <- 3306
user <- 'wbpvp7cmc5uxn70y5aub'
password <- 'pscale_pw_dyI4h8b5i1xm38588e3UxpiqWNTvpGXeUIPw6h3slCe'
rootSSL <- paste0(getwd(),'/V01_conexion-con-bases-de-datos-con-r/cert.pem')
con <- dbConnect(RMariaDB::MariaDB(),
dbname = dbname,
host = host,
port = port,
username = user,
password = password,
ssl.ca = rootSSL)
dbListTables(con) # Lista todas las tablas disponibles en la base de datos
dbWriteTable(con, "mtcars", mtcars) # Para crear tablas
dbListTables(con) # Lista todas las tablas disponibles en la base de datos
dbListTables(con) # Lista todas las tablas disponibles en la base de datos
library(wordcloud)
letters
LETTERS
library(wordcloud)
palabras <- c(letters, LETTERS, 0:9)
frecuenciaPalabras <- sample(1:100,62,TRUE)
library(wordcloud)
palabras <- c(letters, LETTERS, 0:9)
frecuenciaPalabras <- sample(1:100,62,TRUE)
ls("package:wordcloud")
wordcloud(palabras, frecuenciaPalabras)
?wordcloud
library(janeaustenr)
library(tidytext)
library(stringr)
library(dplyr)
library(wordcloud)
books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text,regex("^chapter [\\divxlc]",ignore_case =TRUE)))) %>%
ungroup()
View(books)
data("stop_words")
books_words <- books %>%
unnest_tokens(word, text) %>% anti_join(stop_words)
View(stop_words)
View(books_words)
data("stop_words")
View(stop_words)
books_words <- books %>%
unnest_tokens(word, text) %>% anti_join(stop_words)
View(books_words)
books_words %>%
count(word, sort = TRUE) %>%
with(wordcloud(word, n, max.words = 100))
palabras <- c(letters, LETTERS, 0:9)
frecuenciaPalabras <- sample(1:100,62,TRUE)
View(data.frame(palabra, frecueciaPalabras))
View(data.frame(palabras, frecuenciaPalabras))
ls("package:wordcloud")
library(wordcloud)
ls("package:wordcloud")
wordcloud(palabras, frecuenciaPalabras)
library(janeaustenr)
library(tidytext)
library(stringr)
library(dplyr)
library(wordcloud)
books <- austen_books() %>%
group_by(book) %>%
mutate(linenumber = row_number(),
chapter = cumsum(str_detect(text,regex("^chapter [\\divxlc]",ignore_case =TRUE)))) %>%
ungroup()
View(books)
data("stop_words")
View(stop_words)
books_words <- books %>%
unnest_tokens(word, text) %>% anti_join(stop_words)
View(books_words)
books_words %>%
count(word, sort = TRUE) %>%
with(wordcloud(word, n, max.words = 100))
search()
ls("package:datasets")
str(BOD)
BOD
# Método 1
plot(x=BOD$Time, y=BOD$demand, type='l')
# Método 2
library(ggplot2)
library(dplyr)
BOD %>% ggplot(aes(x=Time, y=demand)) + geom_line()
BOD %>% ggplot(aes(x=Time, y=demand)) +
geom_line() +
ggtitle('Grafico de lineas') +
xlab('Tiempo') +
ylab('Demanda')
class(BOD)
co2
class(co2)
plot(co2)
# Método 3
library(forecast)
ls("package:forecast")
autoplot(co2)
library(reticulate)
repl_python()
import numpy as np
import matpolotlib.pyplo as plt
import matplotlib.pyplo as plt
import matplotlib.pyplot as plt
x = np.array(r.BOD["Time"])
y= np.array(r.BOD["demand"])
plt.plot(x,y)
plt.show()
exit
